BUFFER_SIZE = int(1e6)  # replay buffer size
BATCH_SIZE = 128        # minibatch size
GAMMA = 0.99            # discount factor
TAU = 1e-3              # for soft update of target parameters
LR_ACTOR = 1e-4         # learning rate of the actor 
LR_CRITIC = 3e-4        # learning rate of the critic
WEIGHT_DECAY = 0.0001        # L2 weight decay

Learning Algorithm: Deep Deterministic Policy Gradient (DDPG)
Model Architecture: 3 layers of Neural network:
                     first layer: 33 X 400
                     second layer: 400 X 300
                     third layer: 300 X 4
                        
Plot of Rewards: results.png
Environment was resolved in 401 episodes.
Average scores of last 100 episodes: 30.02
    
Idea of future work: (1) Working on Challenge Crawl, and (2) use other learning algorithms.
